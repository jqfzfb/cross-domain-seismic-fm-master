Cross-domain transfer learning framework that adapts vision foundation models for seismic interpretation.
This repository provides the implementation of our seismic-to-vision bridging strategy, efficient adaptation using LoRA and prefix tuning, geological prompting for structural consistency, and task-adaptive decoders for seismic facies segmentation and related interpretation tasks.

ğŸŒ Overview

Modern deep learning models for seismic interpretation typically rely on task-specific architectures and large labeled datasets.
This project introduces a cross-domain transfer learning framework that repurposes vision foundation models (FMs) for seismic understanding by:

Mapping seismic amplitudes into the latent space of pretrained vision backbones

Adapting FMs efficiently using LoRA and prefix tuning

Embedding geological priors (stratigraphic ordering) into the feature space

Supporting multiple tasks such as facies segmentation, structural interpretation, and attribute prediction

âœ¨ Key Features

ğŸª„ Seismic-to-Vision Bridge: Lightweight module converting seismic amplitudes into vision FM embeddings

ğŸ”§ Efficient FM Adaptation: LoRA + prefix tuning for low-cost, parameter-efficient learning

ğŸ§­ Geological Prompting: Inject stratigraphic constraints into FM latent space

ğŸ§© Task-Adaptive Decoder: Suitable for segmentation or regression tasks

ğŸ“Š Tested on multiple benchmark datasets with diverse geological settings

ğŸ“ Repository Structure
cross-domain-seismic-fm-master/
â”‚
â”œâ”€â”€ models/                 # Bridge, adapters, decoder, LoRA modules
â”œâ”€â”€ sam_backbones/          # Vision foundation model backbones (e.g., SAM)
â”œâ”€â”€ configs/                # Training and data configs
â”œâ”€â”€ scripts/                # Training, evaluation, visualization
â”œâ”€â”€ utils/                  # I/O, transforms, metrics
â””â”€â”€ examples/               # Example inference + visualization


ï¼ˆå¦‚éœ€æˆ‘åŸºäºä½ çœŸå®ç›®å½•ç”Ÿæˆæ›´å‡†ç¡®ç‰ˆæœ¬ï¼Œæˆ‘å¯ä»¥è‡ªåŠ¨è§£æå¹¶å†™å®Œæ•´ä½“ç»“æ„ã€‚ï¼‰

ğŸ“¦ Installation
git clone https://github.com/jqfzfb/cross-domain-seismic-fm-master.git
cd cross-domain-seismic-fm-master

pip install -r requirements.txt

ğŸ“š Datasets

Example seismic data used in the paper can be downloaded from:

ğŸ“Œ Figshare DOI:
https://doi.org/10.6084/m9.figshare.30702569.v1

Benchmark datasets referenced in the manuscript:

Netherlands F3 block â€” Zenodo: https://zenodo.org/records/1471548

Parihaka 3D â€” SEG Wiki: https://wiki.seg.org/wiki/Parihaka-3D

Teapot Dome â€” SEG open datasets

ğŸ”— Pretrained Foundation Model Weights

SAM (Segment Anything Model) pretrained weights are available from:

https://github.com/facebookresearch/segment-anything

Download the desired checkpoint and place it under:

cross-domain-seismic-fm-master/sam_backbones/

ğŸš€ Quick Start
1. Train
python scripts/train.py --config configs/train_fm.yaml

2. Inference
python scripts/inference.py --input path/to/seismic/section.sgy

3. Visualize
python scripts/visualize.py --run path/to/checkpoints/

ğŸ”¬ Citation

If you use this repository, please cite the manuscript:

(ç­‰ä½ è®ºæ–‡çš„æ­£å¼ BibTeXï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”Ÿæˆå®Œæ•´å¼•ç”¨æ ¼å¼)

ğŸ“ License

Specify your license here (MIT, Apache-2.0, GPL, etc.)
Ifä½ å‘Šè¯‰æˆ‘ preferred licenseï¼Œæˆ‘å¯ä»¥åŠ è¿›å»ã€‚

ğŸ™Œ Acknowledgements

This project builds upon:

SAM (Meta AI)

PyTorch

Various open seismic datasets (F3, Parihaka, Teapot Dome)
